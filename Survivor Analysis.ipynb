{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-14T21:41:10.653059Z","iopub.execute_input":"2022-06-14T21:41:10.653549Z","iopub.status.idle":"2022-06-14T21:41:10.696483Z","shell.execute_reply.started":"2022-06-14T21:41:10.653458Z","shell.execute_reply":"2022-06-14T21:41:10.695768Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T21:41:10.701169Z","iopub.execute_input":"2022-06-14T21:41:10.702239Z","iopub.status.idle":"2022-06-14T21:41:10.743559Z","shell.execute_reply.started":"2022-06-14T21:41:10.702192Z","shell.execute_reply":"2022-06-14T21:41:10.742458Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T21:41:10.745257Z","iopub.execute_input":"2022-06-14T21:41:10.745595Z","iopub.status.idle":"2022-06-14T21:41:10.773720Z","shell.execute_reply.started":"2022-06-14T21:41:10.745565Z","shell.execute_reply":"2022-06-14T21:41:10.772934Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Test the assumption that all women survived and all men died:","metadata":{}},{"cell_type":"code","source":"female_survival = train_data.loc[train_data.Sex == \"female\"][\"Survived\"]\nfemale_survival_rate = sum(female_survival) / len(female_survival)\nprint(\"Percentage of women who survived: \" + str(100 * female_survival_rate)[:5] + \"%\")\n\nmale_survival = train_data.loc[train_data.Sex == \"male\"][\"Survived\"]\nmale_survival_rate = sum(male_survival) / len(male_survival)\nprint(\"Percentage of men who survived: \" + str(100 * male_survival_rate)[:5] + \"%\")","metadata":{"execution":{"iopub.status.busy":"2022-06-14T21:41:10.774932Z","iopub.execute_input":"2022-06-14T21:41:10.775252Z","iopub.status.idle":"2022-06-14T21:41:10.792199Z","shell.execute_reply.started":"2022-06-14T21:41:10.775224Z","shell.execute_reply":"2022-06-14T21:41:10.791141Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Use a random forest model to predict survival status based on all other factors:","metadata":{}},{"cell_type":"code","source":"# Create random forest model\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\n# Use these attributes to predict survival rates\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n# Create subset of predictor data and turn categorical values into numerical values\n# X for training predictor data, X_test for testing predictor data\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\n# Create random forest classifier model and train model using training data X and Y\nmodel = RandomForestClassifier(n_estimators = 100, max_depth = 5, random_state = 1)\nmodel.fit(X, y)\n# Predictions using test data, outputs to np.ndarray\npredictions = model.predict(X_test)\n# Convert to pd.DataFrame and save as csv\noutput = pd.DataFrame({\"PassengerId\" : test_data.PassengerId, \"Survived\" : predictions})\noutput.to_csv(\"submission.csv\", index = False)\noutput.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T21:41:10.816185Z","iopub.execute_input":"2022-06-14T21:41:10.816590Z","iopub.status.idle":"2022-06-14T21:41:11.876441Z","shell.execute_reply.started":"2022-06-14T21:41:10.816556Z","shell.execute_reply":"2022-06-14T21:41:11.875294Z"},"trusted":true},"execution_count":5,"outputs":[]}]}